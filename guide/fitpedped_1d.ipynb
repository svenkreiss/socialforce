{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import socialforce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit 1D\n",
    "\n",
    "We start with the simple case where the potential $V(b)$ is approximated only \n",
    "by the classical Social Force potential SF:\n",
    "\\begin{align}\n",
    "    V(b) &= \\textrm{SF}(b) \\\\\n",
    "    \\textrm{SF}(b) &= V_0 \\exp(-b / \\sigma)\n",
    "\\end{align}\n",
    "with its two parameters $V_0$ and $\\sigma$. Although it is a single-parameter\n",
    "function, the parameter $b$ is the semi-minor axis of an ellipse, a 2D object:\n",
    "\\begin{align}\n",
    "    2b &= \\sqrt{||\\vec{r}_{\\alpha\\beta}|| + ||\\vec{r}_{\\alpha\\beta} - v_{\\beta}\\Delta t \\vec{e}_{\\beta}|| - (v_{\\beta}\\Delta t)^2}\n",
    "\\end{align}\n",
    "as defined in {cite}`helbing1995social` with $\\vec{r}_{\\alpha\\beta} = \\vec{r}_{\\alpha} - \\vec{r}_{\\beta}$. \n",
    "We can compare this with $2b = \\sqrt{(p + q)^2 - d^2}$ where the\n",
    "three parameters are the distance to the first focal point $p$,\n",
    "the distance to the second focal point $q$ and the distance between the \n",
    "focal points $d$.\n",
    " \n",
    "\n",
    "\n",
    "## Scenario\n",
    "\n",
    "We generate a single {ref}`Circle scenario <scenarios>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle = socialforce.scenarios.Circle()\n",
    "scenario = circle.generate(1)\n",
    "true_experience = socialforce.Trainer.scenes_to_experience(scenario)\n",
    "\n",
    "with socialforce.show.track_canvas() as ax:\n",
    "    socialforce.show.states(ax, scenario[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "We infer the parameters of an MLP to approximate the 1D scalar \n",
    "function $\\textrm{SF}(b)$ above from synthetic observations.\n",
    "The `PedPedPotentialMLP` is a two-layer MLP with softplus activations:\n",
    "\\begin{align}\n",
    "    \\textrm{MLP}(b) &= \\textrm{Softplus} \\;\\; L_{1\\times5} \\;\\; \\textrm{Softplus} \\;\\; L_{5\\times1} \\;\\; b\n",
    "\\end{align}\n",
    "which is written in terms of linear and non-linear operators where\n",
    "the Softplus operator applies the softplus function on its input from the right\n",
    "and $L$ is a linear operator (a matrix) with the subscript indicating the \n",
    "$\\textrm{output features} \\times \\textrm{input features}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = socialforce.PedPedPotentialMLP().double()\n",
    "initial_state_dict = copy.deepcopy(V.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We use a standard optimizer from PyTorch (SGD).\n",
    "You can specify a standard PyTorch loss function for the `Trainer` as well\n",
    "but here the default of a `torch.nn.SmoothL1Loss(beta=0.05)` is used which is\n",
    "a smooth L1-loss where the closest 5cm are smoothed with a quadratic \n",
    "approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulator_factory(initial_state):\n",
    "    return socialforce.Simulator(initial_state, ped_ped=V)\n",
    "\n",
    "opt = torch.optim.SGD(V.parameters(), lr=10.0)\n",
    "socialforce.Trainer(simulator_factory, opt, true_experience).loop(50, log_interval=10)\n",
    "final_state_dict = copy.deepcopy(V.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "with socialforce.show.canvas(ncols=2) as (ax1, ax2):\n",
    "    socialforce.show.potential1D_parametric(\n",
    "        circle.ped_ped, ax1, ax2, \n",
    "        label=r'true $V_0 e^{-b/\\sigma}$', sigma_label=r'true $\\sigma$', color='gray')\n",
    "\n",
    "    V.load_state_dict(initial_state_dict)\n",
    "    socialforce.show.potential1D(V, ax1, ax2, label=r'initial MLP($b$)', linestyle='dashed', color='C0')\n",
    "\n",
    "    V.load_state_dict(final_state_dict)\n",
    "    socialforce.show.potential1D(V, ax1, ax2, label=r'MLP($b$)', color='C0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generated a single synthetic scene with two pedestrians with a parametric\n",
    "potential that was the standard Social Force potential. \n",
    "That parametric potential is shown in gray in the above plot.\n",
    "Then we trained an MLP\n",
    "to infer its parameters. In the above plot, you see the MLP with its initialized\n",
    "random parameters as a dashed line and with its inferred parameters as a solid \n",
    "line. During the training process, the function values of the generating potential\n",
    "were never accessed. Only observed simulation steps were used to train the potential."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('venv3': venv)",
   "metadata": {
    "interpreter": {
     "hash": "29864609ce42acb949f1cb2f5c54bbb80a5cac9b20d76f096c9b799bd2af5ed7"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
